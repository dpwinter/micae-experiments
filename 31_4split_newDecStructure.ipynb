{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4-split seems to train way worse than with the old structure. It seems less Dense layers close to the bottleneck cope better with translated images.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Conv2D, Conv2DTranspose, Dense, Input, Reshape, concatenate, Activation, Dropout\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sys; sys.path.insert(0, '..')\n",
    "import utils\n",
    "\n",
    "class MultiSplit(Model):\n",
    "    def __init__(self, n_splits, latent_dim, io_shape):\n",
    "        super(MultiSplit, self).__init__()\n",
    "        n_filters = [32, 64]\n",
    "        size = int( io_shape[0] // (n_splits**(1/2)) )  # W = H\n",
    "        self.encoder = self._create_encoder(latent_dim//n_splits, (size, size,1), n_filters)\n",
    "        self.input_reshaper = utils.Reshaper((n_splits, size, size, 1), (size, size,1))\n",
    "        self.latent_reshaper = utils.Reshaper([latent_dim//n_splits], [latent_dim])\n",
    "#         self.regressor = self._create_regressor(latent_dim)\n",
    "#         self.classifier = self._create_classifier(latent_dim)\n",
    "        self.decoder = self._create_decoder(latent_dim, io_shape, n_filters)\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(x, training=False)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, x, training=True):\n",
    "        z = self.encode(x, training=training)\n",
    "        y_pred = self.decode(z ,training=training)\n",
    "#         y_pred = self.classify(z ,training=training)\n",
    "#         y_pred = self.regress(z ,training=training)\n",
    "        return y_pred\n",
    "        \n",
    "    def encode(self, x, training=True):\n",
    "        return self.encoder( self.input_reshaper(x) , training)\n",
    "    \n",
    "    def decode(self, z, training=True):\n",
    "        return self.decoder( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def classify(self, z, training=True):\n",
    "        return self.classifier( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def regress(self, z, training=True):\n",
    "        return self.regressor( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def _create_encoder(self, latent_dim, input_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=input_shape),\n",
    "            Conv2D(filters=n_filters[0], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Conv2D(filters=n_filters[1], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Conv2D(filters=1, kernel_size=(1,1), strides=(1,1), activation='sigmoid', padding='same', name='pt_conv'),  # Introduce point convolution at end\n",
    "            Flatten(),\n",
    "            Dense(units=latent_dim)\n",
    "        ], name='encoder')\n",
    "\n",
    "    def _create_decoder(self, latent_dim, io_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense((io_shape[0]-4)*(io_shape[1]-4)),\n",
    "            Reshape((io_shape[0]-4,io_shape[1]-4,1)),\n",
    "            Conv2DTranspose(filters=n_filters[1], kernel_size=(3,3), strides=(1,1), activation='relu', padding='valid'),\n",
    "            Conv2DTranspose(filters=n_filters[0], kernel_size=(3,3), strides=(1,1), activation='relu', padding='valid'),\n",
    "            Conv2DTranspose(filters=1, kernel_size=(1,1), padding='valid'),\n",
    "            Activation('sigmoid', name='decoder_out')\n",
    "        ])\n",
    "    \n",
    "    def _create_classifier(self, latent_dim):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    def _create_regressor(self, latent_dim):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(2, activation='linear')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 4\n",
    "io_shape = (28,28,1)\n",
    "size = int(io_shape[0] // (n_splits**(1/2)))\n",
    "latent_dim = 16\n",
    "\n",
    "model = MultiSplit(n_splits, latent_dim, io_shape)\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train_split = np.array([utils.split(x, size, size) for x in x_train], dtype='float32')\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test_split = np.array([utils.split(x, size, size) for x in x_test], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0336 - val_loss: 0.0202\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0196 - val_loss: 0.0187\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0172 - val_loss: 0.0163\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0166 - val_loss: 0.0160\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0161 - val_loss: 0.0155\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0148 - val_loss: 0.0143\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0146 - val_loss: 0.0141\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0143 - val_loss: 0.0138\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0141 - val_loss: 0.0136\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0138 - val_loss: 0.0134\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0136 - val_loss: 0.0132\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0130 - val_loss: 0.0127\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0129 - val_loss: 0.0127\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0128 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0120 - val_loss: 0.0119\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(x_train_split, x_train, validation_data=(x_test_split, x_test), epochs=50, batch_size=32)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Pretrain 1-split reconstruction loss')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "plt.savefig('../img/31/CE4_newDecoderStruct_epoch50.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.save_weights('../weights/31_CE4x4_epoch50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, add more units in the decoder, close to bottleneck. This definitly seems to help, although for 16-split it breaks training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Conv2D, Conv2DTranspose, Dense, Input, Reshape, concatenate, Activation, Dropout\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sys; sys.path.insert(0, '..')\n",
    "import utils\n",
    "\n",
    "class MultiSplit(Model):\n",
    "    def __init__(self, n_splits, latent_dim, io_shape):\n",
    "        super(MultiSplit, self).__init__()\n",
    "        n_filters = [32, 64]\n",
    "        size = int( io_shape[0] // (n_splits**(1/2)) )  # W = H\n",
    "        self.encoder = self._create_encoder(latent_dim//n_splits, (size, size,1), n_filters)\n",
    "        self.input_reshaper = utils.Reshaper((n_splits, size, size, 1), (size, size,1))\n",
    "        self.latent_reshaper = utils.Reshaper([latent_dim//n_splits], [latent_dim])\n",
    "#         self.regressor = self._create_regressor(latent_dim)\n",
    "#         self.classifier = self._create_classifier(latent_dim)\n",
    "        self.decoder = self._create_decoder(latent_dim, io_shape, n_filters)\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(x, training=False)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, x, training=True):\n",
    "        z = self.encode(x, training=training)\n",
    "        y_pred = self.decode(z ,training=training)\n",
    "#         y_pred = self.classify(z ,training=training)\n",
    "#         y_pred = self.regress(z ,training=training)\n",
    "        return y_pred\n",
    "        \n",
    "    def encode(self, x, training=True):\n",
    "        return self.encoder( self.input_reshaper(x) , training)\n",
    "    \n",
    "    def decode(self, z, training=True):\n",
    "        return self.decoder( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def classify(self, z, training=True):\n",
    "        return self.classifier( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def regress(self, z, training=True):\n",
    "        return self.regressor( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def _create_encoder(self, latent_dim, input_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=input_shape),\n",
    "            Conv2D(filters=n_filters[0], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Conv2D(filters=n_filters[1], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Conv2D(filters=1, kernel_size=(1,1), strides=(1,1), activation='linear', padding='same', name='pt_conv'),  # Introduce point convolution at end\n",
    "            Flatten(),\n",
    "            Dense(units=latent_dim)\n",
    "        ], name='encoder')\n",
    "\n",
    "    def _create_decoder(self, latent_dim, io_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense((io_shape[0]-4)*(io_shape[1]-4)*32),\n",
    "            Reshape((io_shape[0]-4,io_shape[1]-4,32)),\n",
    "            Conv2DTranspose(filters=n_filters[1], kernel_size=(3,3), strides=(1,1), activation='relu', padding='valid'),\n",
    "            Conv2DTranspose(filters=n_filters[0], kernel_size=(3,3), strides=(1,1), activation='relu', padding='valid'),\n",
    "            Conv2DTranspose(filters=1, kernel_size=(1,1), padding='valid'),\n",
    "            Activation('sigmoid', name='decoder_out')\n",
    "        ])\n",
    "    \n",
    "    def _create_classifier(self, latent_dim):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    def _create_regressor(self, latent_dim):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(2, activation='linear')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 4\n",
    "io_shape = (28,28,1)\n",
    "size = int(io_shape[0] // (n_splits**(1/2)))\n",
    "latent_dim = 16\n",
    "\n",
    "model = MultiSplit(n_splits, latent_dim, io_shape)\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train_split = np.array([utils.split(x, size, size) for x in x_train], dtype='float32')\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test_split = np.array([utils.split(x, size, size) for x in x_test], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0230 - val_loss: 0.0157\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0149 - val_loss: 0.0138\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0092 - val_loss: 0.0099\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(x_train_split, x_train, validation_data=(x_test_split, x_test), epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about getting rid of the point convolution at the end of the encoder? That improves things even more.. So the mechanisms responsible for performance improvement for 4-split are the reason the training comes to a halt for 16-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Conv2D, Conv2DTranspose, Dense, Input, Reshape, concatenate, Activation, Dropout\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sys; sys.path.insert(0, '..')\n",
    "import utils\n",
    "\n",
    "class MultiSplit(Model):\n",
    "    def __init__(self, n_splits, latent_dim, io_shape):\n",
    "        super(MultiSplit, self).__init__()\n",
    "        n_filters = [32, 64]\n",
    "        size = int( io_shape[0] // (n_splits**(1/2)) )  # W = H\n",
    "        self.encoder = self._create_encoder(latent_dim//n_splits, (size, size,1), n_filters)\n",
    "        self.input_reshaper = utils.Reshaper((n_splits, size, size, 1), (size, size,1))\n",
    "        self.latent_reshaper = utils.Reshaper([latent_dim//n_splits], [latent_dim])\n",
    "#         self.regressor = self._create_regressor(latent_dim)\n",
    "#         self.classifier = self._create_classifier(latent_dim)\n",
    "        self.decoder = self._create_decoder(latent_dim, io_shape, n_filters)\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(x, training=False)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, x, training=True):\n",
    "        z = self.encode(x, training=training)\n",
    "        y_pred = self.decode(z ,training=training)\n",
    "#         y_pred = self.classify(z ,training=training)\n",
    "#         y_pred = self.regress(z ,training=training)\n",
    "        return y_pred\n",
    "        \n",
    "    def encode(self, x, training=True):\n",
    "        return self.encoder( self.input_reshaper(x) , training)\n",
    "    \n",
    "    def decode(self, z, training=True):\n",
    "        return self.decoder( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def classify(self, z, training=True):\n",
    "        return self.classifier( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def regress(self, z, training=True):\n",
    "        return self.regressor( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def _create_encoder(self, latent_dim, input_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=input_shape),\n",
    "            Conv2D(filters=n_filters[0], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Conv2D(filters=n_filters[1], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Flatten(),\n",
    "            Dense(units=latent_dim)\n",
    "        ], name='encoder')\n",
    "\n",
    "    def _create_decoder(self, latent_dim, io_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense((io_shape[0]-4)*(io_shape[1]-4)*32),\n",
    "            Reshape((io_shape[0]-4,io_shape[1]-4,32)),\n",
    "            Conv2DTranspose(filters=n_filters[1], kernel_size=(3,3), strides=(1,1), activation='relu', padding='valid'),\n",
    "            Conv2DTranspose(filters=n_filters[0], kernel_size=(3,3), strides=(1,1), activation='relu', padding='valid'),\n",
    "            Conv2DTranspose(filters=1, kernel_size=(1,1), padding='valid'),\n",
    "            Activation('sigmoid', name='decoder_out')\n",
    "        ])\n",
    "    \n",
    "    def _create_classifier(self, latent_dim):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    def _create_regressor(self, latent_dim):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(2, activation='linear')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 4\n",
    "io_shape = (28,28,1)\n",
    "size = int(io_shape[0] // (n_splits**(1/2)))\n",
    "latent_dim = 16\n",
    "\n",
    "model = MultiSplit(n_splits, latent_dim, io_shape)\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train_split = np.array([utils.split(x, size, size) for x in x_train], dtype='float32')\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test_split = np.array([utils.split(x, size, size) for x in x_test], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0202 - val_loss: 0.0128\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0082 - val_loss: 0.0087\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0077 - val_loss: 0.0084\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(x_train_split, x_train, validation_data=(x_test_split, x_test), epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check wo/ point conv, but with reduced decoder Reshape layer. We see only the combination of many channels before and after the latent space gives good reco loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Conv2D, Conv2DTranspose, Dense, Input, Reshape, concatenate, Activation, Dropout\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sys; sys.path.insert(0, '..')\n",
    "import utils\n",
    "\n",
    "class MultiSplit(Model):\n",
    "    def __init__(self, n_splits, latent_dim, io_shape):\n",
    "        super(MultiSplit, self).__init__()\n",
    "        n_filters = [32, 64]\n",
    "        size = int( io_shape[0] // (n_splits**(1/2)) )  # W = H\n",
    "        self.encoder = self._create_encoder(latent_dim//n_splits, (size, size,1), n_filters)\n",
    "        self.input_reshaper = utils.Reshaper((n_splits, size, size, 1), (size, size,1))\n",
    "        self.latent_reshaper = utils.Reshaper([latent_dim//n_splits], [latent_dim])\n",
    "#         self.regressor = self._create_regressor(latent_dim)\n",
    "#         self.classifier = self._create_classifier(latent_dim)\n",
    "        self.decoder = self._create_decoder(latent_dim, io_shape, n_filters)\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(x, training=False)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, x, training=True):\n",
    "        z = self.encode(x, training=training)\n",
    "        y_pred = self.decode(z ,training=training)\n",
    "#         y_pred = self.classify(z ,training=training)\n",
    "#         y_pred = self.regress(z ,training=training)\n",
    "        return y_pred\n",
    "        \n",
    "    def encode(self, x, training=True):\n",
    "        return self.encoder( self.input_reshaper(x) , training)\n",
    "    \n",
    "    def decode(self, z, training=True):\n",
    "        return self.decoder( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def classify(self, z, training=True):\n",
    "        return self.classifier( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def regress(self, z, training=True):\n",
    "        return self.regressor( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def _create_encoder(self, latent_dim, input_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=input_shape),\n",
    "            Conv2D(filters=n_filters[0], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Conv2D(filters=n_filters[1], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Flatten(),\n",
    "            Dense(units=latent_dim)\n",
    "        ], name='encoder')\n",
    "\n",
    "    def _create_decoder(self, latent_dim, io_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense((io_shape[0]-4)*(io_shape[1]-4)),\n",
    "            Reshape((io_shape[0]-4,io_shape[1]-4,1)),\n",
    "            Conv2DTranspose(filters=n_filters[1], kernel_size=(3,3), strides=(1,1), activation='relu', padding='valid'),\n",
    "            Conv2DTranspose(filters=n_filters[0], kernel_size=(3,3), strides=(1,1), activation='relu', padding='valid'),\n",
    "            Conv2DTranspose(filters=1, kernel_size=(1,1), padding='valid'),\n",
    "            Activation('sigmoid', name='decoder_out')\n",
    "        ])\n",
    "    \n",
    "    def _create_classifier(self, latent_dim):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    def _create_regressor(self, latent_dim):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(2, activation='linear')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 4\n",
    "io_shape = (28,28,1)\n",
    "size = int(io_shape[0] // (n_splits**(1/2)))\n",
    "latent_dim = 16\n",
    "\n",
    "model = MultiSplit(n_splits, latent_dim, io_shape)\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train_split = np.array([utils.split(x, size, size) for x in x_train], dtype='float32')\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test_split = np.array([utils.split(x, size, size) for x in x_test], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0251 - val_loss: 0.0164\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0156 - val_loss: 0.0142\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0142 - val_loss: 0.0134\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0131 - val_loss: 0.0128\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0111 - val_loss: 0.0109\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(x_train_split, x_train, validation_data=(x_test_split, x_test), epochs=25, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
