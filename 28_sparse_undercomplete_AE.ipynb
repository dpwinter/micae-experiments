{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Conv2D, Conv2DTranspose, Dense, Input, Reshape, concatenate, Activation, Dropout\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sys; sys.path.insert(0, '..')\n",
    "import utils\n",
    "\n",
    "class MultiSplit(Model):\n",
    "    def __init__(self, n_splits, latent_dim, io_shape):\n",
    "        super(MultiSplit, self).__init__()\n",
    "        n_filters = [32, 64]\n",
    "        size = int( io_shape[0] // (n_splits**(1/2)) )  # W = H\n",
    "        self.encoder = self._create_encoder(latent_dim//n_splits, (size, size,1), n_filters)\n",
    "        self.input_reshaper = utils.Reshaper((n_splits, size, size, 1), (size, size,1))\n",
    "        self.latent_reshaper = utils.Reshaper([latent_dim//n_splits], [latent_dim])\n",
    "        self.classifier = self._create_classifier(latent_dim)\n",
    "#         self.decoder = self._create_decoder(latent_dim, io_shape, n_filters)\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(x, training=False)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, x, training=True):\n",
    "        z = self.encode(x, training=training)\n",
    "#         y_pred = self.decode(z ,training=training)\n",
    "        y_pred = self.classify(z ,training=training)\n",
    "        return y_pred\n",
    "        \n",
    "    def encode(self, x, training=True):\n",
    "        return self.encoder( self.input_reshaper(x) , training)\n",
    "    \n",
    "    def decode(self, z, training=True):\n",
    "        return self.decoder( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def classify(self, z, training=True):\n",
    "        return self.classifier( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def _create_encoder(self, latent_dim, input_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=input_shape),\n",
    "            Conv2D(filters=n_filters[0], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Conv2D(filters=n_filters[1], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Flatten(),\n",
    "            Dense(units=latent_dim, activity_regularizer=keras.regularizers.l1(0.001))\n",
    "        ], name='encoder')\n",
    "\n",
    "    def _create_decoder(self, latent_dim, io_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense(io_shape[0]//4 * io_shape[1]//4 * n_filters[0]),  # factor 4 due to conv.\n",
    "            Reshape((io_shape[0]//4, io_shape[1]//4, n_filters[0])),\n",
    "            Conv2DTranspose(filters=n_filters[1], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Conv2DTranspose(filters=n_filters[0], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Conv2DTranspose(filters=1, kernel_size=(3,3), padding='same'),\n",
    "            Activation('sigmoid', name='decoder_out')\n",
    "        ])\n",
    "    \n",
    "    def _create_classifier(self, latent_dim):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrain with regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 1\n",
    "io_shape = (28,28,1)\n",
    "size = int(io_shape[0] // (n_splits**(1/2)))\n",
    "latent_dim = 16\n",
    "\n",
    "model = MultiSplit(n_splits, latent_dim, io_shape)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train_split = np.array([utils.split(x, size, size) for x in x_train], dtype='float32')\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test_split = np.array([utils.split(x, size, size) for x in x_test], dtype='float32')\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0222 - val_loss: 0.0106\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0068 - val_loss: 0.0070\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0064 - val_loss: 0.0067\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam') # COMPILE AFTER WEIGHTS LOADED\n",
    "\n",
    "history = model.fit(x_train_split, x_train, validation_data=(x_test_split, x_test), epochs=25, batch_size=32)\n",
    "model.encoder.save_weights('../weights/28_CE16_sparse_epoch25.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load weights in another model and train classifier. (set encoder non trainable also fixes regularizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0043 - accuracy: 0.9730 - val_loss: 0.0047 - val_accuracy: 0.9701\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0042 - accuracy: 0.9729 - val_loss: 0.0046 - val_accuracy: 0.9706\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0042 - accuracy: 0.9730 - val_loss: 0.0046 - val_accuracy: 0.9707\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0042 - accuracy: 0.9734 - val_loss: 0.0047 - val_accuracy: 0.9689\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0042 - accuracy: 0.9732 - val_loss: 0.0045 - val_accuracy: 0.9718\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0041 - accuracy: 0.9738 - val_loss: 0.0047 - val_accuracy: 0.9694\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0041 - accuracy: 0.9743 - val_loss: 0.0048 - val_accuracy: 0.9697\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0041 - accuracy: 0.9739 - val_loss: 0.0046 - val_accuracy: 0.9707\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0041 - accuracy: 0.9741 - val_loss: 0.0046 - val_accuracy: 0.9709\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0041 - accuracy: 0.9740 - val_loss: 0.0046 - val_accuracy: 0.9710\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0041 - accuracy: 0.9742 - val_loss: 0.0047 - val_accuracy: 0.9711\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 0.9746 - val_loss: 0.0046 - val_accuracy: 0.9717\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 0.9747 - val_loss: 0.0045 - val_accuracy: 0.9718\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 0.9744 - val_loss: 0.0046 - val_accuracy: 0.9708\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 0.9749 - val_loss: 0.0044 - val_accuracy: 0.9718\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 0.9746 - val_loss: 0.0046 - val_accuracy: 0.9717\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 0.9752 - val_loss: 0.0047 - val_accuracy: 0.9699\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9748 - val_loss: 0.0046 - val_accuracy: 0.9708\n",
      "Epoch 19/25\n",
      " 999/1875 [==============>...............] - ETA: 1s - loss: 0.0039 - accuracy: 0.9750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6ba1a3e33ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# COMPILE AFTER WEIGHTS LOADED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[1;32m    303\u001b[0m         delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m     \"\"\"\n\u001b[0;32m-> 3494\u001b[0;31m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0m\u001b[1;32m   3495\u001b[0m                     overwrite_input=overwrite_input)\n\u001b[1;32m   3496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3401\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3403\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3404\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3546\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3547\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3548\u001b[0;31m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3550\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3332\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3334\u001b[0;31m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[1;32m   3335\u001b[0m                           out=out, **kwargs)\n\u001b[1;32m   3336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = MultiSplit(n_splits, latent_dim, io_shape)\n",
    "\n",
    "# model.encoder.load_weights('../weights/28_CE16_sparse_epoch25.h5')\n",
    "# for layer in model.encoder.layers:\n",
    "#     layer.trainable = False\n",
    "    \n",
    "model.compile(loss='mse', metrics=['accuracy'], optimizer='adam') # COMPILE AFTER WEIGHTS LOADED\n",
    "\n",
    "history = model.fit(x_train_split, y_train, validation_data=(x_test_split, y_test), epochs=25, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
