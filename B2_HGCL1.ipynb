{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "# from qkeras import QConv2D, QDense\n",
    "# from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict\n",
    "\n",
    "# q_relu = quantized_relu(9, 5)\n",
    "# q_bits = quantized_bits(9, 5)\n",
    "\n",
    "latent_dims  = [8,8,8,8,8]    # test for all same latent dims\n",
    "multiplicity = [3,3,19,30] # sectors/roc, rocs/module, modules/layer, layers\n",
    "\n",
    "def conv_encoder(output_dims):\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Input(shape=(4,4,1)),\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=(2,2), strides=(1,1), padding='valid', activation='relu'),\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=(2,2), strides=(1,1), padding='valid', activation='relu'),\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=(2,2), strides=(1,1), padding='valid', activation='relu'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dense(units=256, activation='relu'),\n",
    "        keras.layers.Dense(units=output_dims, activation='linear')\n",
    "\n",
    "#         QConv2D(filters=64, kernel_size=(2,2), strides=(1,1), activation=q_relu, padding='valid', kernel_quantizer=q_bits, bias_quantizer=q_bits),\n",
    "#         QConv2D(filters=64, kernel_size=(2,2), strides=(1,1), activation=q_relu, padding='valid', kernel_quantizer=q_bits, bias_quantizer=q_bits),\n",
    "#         QConv2D(filters=64, kernel_size=(2,2), strides=(1,1), activation=q_relu, padding='valid', kernel_quantizer=q_bits, bias_quantizer=q_bits),\n",
    "#         keras.layers.Flatten(),\n",
    "#         QDense(units=128, activation=q_relu, kernel_quantizer=q_bits, bias_quantizer=q_bits),\n",
    "#         QDense(units=256, activation=q_relu, kernel_quantizer=q_bits, bias_quantizer=q_bits),\n",
    "#         QDense(units=output_dims, activation=q_bits, kernel_quantizer=q_bits, bias_quantizer=q_bits)\n",
    "    ])\n",
    "\n",
    "def conv_decoder(input_dims):\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Input(shape=(input_dims)),\n",
    "        keras.layers.Dense(units=256, activation='relu'),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Reshape(target_shape=(1,1,128)),\n",
    "        keras.layers.Conv2DTranspose(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "        keras.layers.Conv2DTranspose(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=(2,2), strides=(1,1), padding='valid', activation='relu'),\n",
    "        keras.layers.Conv2D(filters=1, kernel_size=(1,1), strides=(1,1), padding='valid', activation='relu')\n",
    "    ])\n",
    "\n",
    "def encoder(input_dims, output_dims, n):\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Input(shape=(n*input_dims)),\n",
    "        keras.layers.Dense(units=32, activation='relu'),\n",
    "        keras.layers.Dense(units=64, activation='relu'),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dense(units=256, activation='relu'),\n",
    "        keras.layers.Dense(output_dims, activation='linear')\n",
    "\n",
    "#         QDense(units=32, activation=q_relu, kernel_quantizer=q_bits, bias_quantizer=q_bits),\n",
    "#         QDense(units=64, activation=q_relu, kernel_quantizer=q_bits, bias_quantizer=q_bits),\n",
    "#         QDense(units=128, activation=q_relu, kernel_quantizer=q_bits, bias_quantizer=q_bits),\n",
    "#         QDense(units=256, activation=q_relu, kernel_quantizer=q_bits, bias_quantizer=q_bits),\n",
    "#         QDense(output_dims, activation=q_bits, kernel_quantizer=q_bits, bias_quantizer=q_bits)\n",
    "    ])\n",
    "\n",
    "def decoder(input_dims, output_dims, n):\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Input(shape=input_dims),\n",
    "        keras.layers.Dense(units=256, activation='linear'),\n",
    "        keras.layers.Dense(units=128, activation='linear'),\n",
    "        keras.layers.Dense(units=64, activation='linear'),\n",
    "        keras.layers.Dense(units=32, activation='linear'),\n",
    "        keras.layers.Dense(units=n*output_dims, activation='linear'),\n",
    "    ])\n",
    "\n",
    "class Reshaper(keras.models.Model):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        model_in  = keras.layers.Input(shape=input_shape)\n",
    "        model_out = K.concatenate((K.variable([-1], dtype='int32'), output_shape))\n",
    "        shaper = keras.layers.Lambda(lambda x: K.reshape(x, model_out))(model_in)\n",
    "        super(Reshaper, self).__init__(inputs=model_in, outputs=shaper)\n",
    "\n",
    "class TPG(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(TPG, self).__init__()\n",
    "        self.encoders = OrderedDict({\n",
    "            'ROC' : conv_encoder(output_dims=latent_dims[0]),\n",
    "            'MOD' : encoder(input_dims=latent_dims[0], output_dims=latent_dims[1], n=multiplicity[0]),\n",
    "            'TRI' : encoder(input_dims=latent_dims[1], output_dims=latent_dims[2], n=multiplicity[1]),\n",
    "            'ST1' : encoder(input_dims=latent_dims[2], output_dims=latent_dims[3], n=multiplicity[2]),\n",
    "            'ST2' : encoder(input_dims=latent_dims[3], output_dims=latent_dims[4], n=multiplicity[3])\n",
    "        })\n",
    "        self.decoders = OrderedDict({\n",
    "            'ST2' : decoder(input_dims=latent_dims[4], output_dims=latent_dims[3], n=multiplicity[3]),\n",
    "            'ST1' : decoder(input_dims=latent_dims[3], output_dims=latent_dims[2], n=multiplicity[2]),\n",
    "            'TRI' : decoder(input_dims=latent_dims[2], output_dims=latent_dims[1], n=multiplicity[1]),\n",
    "            'MOD' : decoder(input_dims=latent_dims[1], output_dims=latent_dims[0], n=multiplicity[0]),\n",
    "            'ROC' : conv_decoder(input_dims=latent_dims[0])\n",
    "        })\n",
    "        self.encoder_reshapers = OrderedDict({\n",
    "            'ROC' : Reshaper([30,19,3,3, 4,4,1], [4,4,1]),\n",
    "            'MOD' : Reshaper([latent_dims[0]], [3 *latent_dims[0]]),\n",
    "            'TRI' : Reshaper([latent_dims[1]], [3 *latent_dims[1]]),\n",
    "            'ST1' : Reshaper([latent_dims[2]], [19*latent_dims[2]]),\n",
    "            'ST2' : Reshaper([latent_dims[3]], [30*latent_dims[3]])\n",
    "        })\n",
    "        self.decoder_reshapers = OrderedDict({\n",
    "            'ST2' : Reshaper([30*latent_dims[3]], [latent_dims[3]]),\n",
    "            'ST1' : Reshaper([19*latent_dims[2]], [latent_dims[2]]),\n",
    "            'TRI' : Reshaper([3 *latent_dims[1]], [latent_dims[1]]),\n",
    "            'MOD' : Reshaper([3 *latent_dims[0]], [latent_dims[0]]),\n",
    "            'ROC' : Reshaper([4,4,1], [30,19,3,3, 4,4,1])\n",
    "        })\n",
    "        self.depth = 5  # depth of autoencoding\n",
    "    \n",
    "    def encode(self, x, training=True):\n",
    "        for level, encoder in list(self.encoders.items())[:self.depth]:\n",
    "            x = self.encoders[level](self.encoder_reshapers[level](x), training=training)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, training=True):\n",
    "        for level, decoder in list(self.decoders.items())[-self.depth:]:\n",
    "            x = self.decoder_reshapers[level](self.decoders[level](x), training=training)\n",
    "        return x\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(x, training=False)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, x, training=True):\n",
    "        z = self.encode(x, training=training)\n",
    "        y = self.decode(z, training=training)\n",
    "        return y\n",
    "    \n",
    "    def set_trainable(self, d):\n",
    "        if type(d) != dict:\n",
    "            raise TypeError(\"set_trainable expected input type dict.\")\n",
    "        else:\n",
    "            for k, v in d.items():\n",
    "                self.encoders[k].trainable = int(v)\n",
    "                self.decoders[k].trainable = int(v)\n",
    "        self.depth = [idx+1 for idx, item in enumerate(d.values()) if item != 0][-1]\n",
    "        self.compile(loss=self.loss, optimizer=self.optimizer)  # recompile model AFTER setting trainable attributes.\n",
    "        return {k : (self.encoders[k].trainable, self.decoders[k].trainable) for k in d.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pickle.load(open('/home/don/Desktop/electrons_config1_1_to_500GeV_4Tesla.pickle', 'rb'))\n",
    "x_train = data['digi'][:800].reshape(800,30,19,3,3,4,4,1)\n",
    "x_test = data['digi'][800:].reshape(200,30,19,3,3,4,4,1)\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "400/400 [==============================] - 265s 663ms/step - loss: 3.6324 - val_loss: 3.4411\n",
      "Epoch 2/4\n",
      "400/400 [==============================] - 258s 646ms/step - loss: 3.3182 - val_loss: 3.4507\n",
      "Epoch 3/4\n",
      "400/400 [==============================] - 262s 655ms/step - loss: 3.2942 - val_loss: 3.4072\n",
      "Epoch 4/4\n",
      "400/400 [==============================] - 257s 642ms/step - loss: 3.3001 - val_loss: 3.4097\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "tf.config.optimizer.set_experimental_options({'layout_optimizer':0}) # prevent reshaping from NWHC to NCWH for GPU usage optimization\n",
    "\n",
    "opt = keras.optimizers.Adam(1e-4)\n",
    "trainable_dict = {'ROC':1, 'MOD':1, 'TRI':1, 'ST1':1, 'ST2':1}\n",
    "\n",
    "# with tf.device('/GPU:0'):  # too much for my poor GPU :(\n",
    "with tf.device('/CPU:0'):\n",
    "    model = TPG()\n",
    "    model.compile(loss='mse', optimizer=opt)\n",
    "    model.set_trainable(trainable_dict)\n",
    "    model.fit(x_train, x_train, validation_data=(x_test, x_test), epochs=4, batch_size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
