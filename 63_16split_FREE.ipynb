{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Conv2D, Conv2DTranspose, Dense, Input, Reshape\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# encoder\n",
    "latents = []\n",
    "enc_inputs = [Input(shape=(14,14,1)) for _ in range(16)]\n",
    "conv1 = Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), activation='relu', padding='same')\n",
    "conv2 = Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), activation='relu', padding='same')\n",
    "flatten = Flatten()\n",
    "latent = Dense(units=4, activation='sigmoid')\n",
    "\n",
    "for i in range(16):\n",
    "    enc_out = latent(flatten(conv2(conv1(enc_inputs[i]))))\n",
    "    latents.append(enc_out)\n",
    "latent_concat = keras.layers.concatenate(latents, name='latent_concat')\n",
    "\n",
    "# decoder\n",
    "dec_input = Input(shape=(4*16,), name='dec_input')\n",
    "x = Dense(units=1568, activation='relu', name='dense')(dec_input)\n",
    "x = Reshape(target_shape=(14,14,8), name='reshape')(x)\n",
    "x = Conv2DTranspose(filters=64, kernel_size=3, strides=2, activation='relu', padding='same', name='deconv1')(x)\n",
    "x = Conv2DTranspose(filters=32, kernel_size=3, strides=2, activation='relu', padding='same', name='deconv2')(x)\n",
    "dec_output = Conv2DTranspose(filters=1, kernel_size=3, padding='same', name='pt_conv')(x)\n",
    "\n",
    "\n",
    "class customModel(Model):\n",
    "    def test_step(self, data):\n",
    "        x, y, y_regr = data\n",
    "        y_pred = self(x, training=False)\n",
    "        y_pred = tf.image.extract_glimpse(y_pred, (28,28), y_regr, centered=False, normalized=False, noise='zero')\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "        \n",
    "        \n",
    "encoders = [Model(enc_inputs[i], latents[i], name='Encoder_%d'%i) for i in range(16)]\n",
    "decoder = Model(dec_input, dec_output, name=\"Decoder\")\n",
    "model = customModel(enc_inputs, decoder(latent_concat))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "def split(im, nrows, ncols):\n",
    "    # split 'im' (w*h*c) array into n equal parts.\n",
    "    width, height = im.shape[:-1]\n",
    "    im = im.reshape(height//nrows, nrows, -1, ncols)  # split in n 2d arrays along cols\n",
    "    im = im.swapaxes(1, 2)     # restore order: zig-zag\n",
    "    im = im.reshape(-1, nrows, ncols, 1) # x 2d arrays with new dims + channel\n",
    "    return im\n",
    "\n",
    "def embed_and_translate(data, n_width, n_height):\n",
    "    ndata = np.zeros((len(data), n_width, n_height, 1), dtype='float32')\n",
    "    translations = np.empty((len(data), 2), dtype='float32')\n",
    "    width, height = data.shape[1], data.shape[2]\n",
    "    for i in range(len(data)):\n",
    "        x = np.random.randint(n_width-width)\n",
    "        y = np.random.randint(n_height-height)\n",
    "        ndata[i][x:x+width, y:y+height] = data[i] # rows, cols = height, width\n",
    "        translations[i][0] = x+(width//2)\n",
    "        translations[i][1] = y+(height//2)\n",
    "    return ndata, translations\n",
    "\n",
    "# !!! eval loss at right position!\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train_augmented, _ = embed_and_translate(x_train, 56, 56)\n",
    "x_train = None\n",
    "x_train_split = np.array([split(x, 14, 14) for x in x_train_augmented], dtype='float32')\n",
    "x_train_split = x_train_split.swapaxes(0,1)\n",
    "x_train_split = [x for x in x_train_split]\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test_augmented, y_test_regr = embed_and_translate(x_test, 56, 56)\n",
    "x_test_split = np.array([split(x, 14, 14) for x in x_test_augmented], dtype='float32')\n",
    "x_test_augmented = None\n",
    "x_test_split = x_test_split.swapaxes(0,1)\n",
    "x_test_split = [x for x in x_test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0133 - val_loss: 0.0436\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0103 - val_loss: 0.0391\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0097 - val_loss: 0.0377\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0094 - val_loss: 0.0371\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0091 - val_loss: 0.0360\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0089 - val_loss: 0.0361\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0088 - val_loss: 0.0348\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0087 - val_loss: 0.0343\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0086 - val_loss: 0.0338\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0085 - val_loss: 0.0334\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.0084 - val_loss: 0.0334\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0083 - val_loss: 0.0328\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.0083 - val_loss: 0.0325\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.0082 - val_loss: 0.0325\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0081 - val_loss: 0.0327\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0081 - val_loss: 0.0322\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0080 - val_loss: 0.0320\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.0080 - val_loss: 0.0318\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0080 - val_loss: 0.0317\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0079 - val_loss: 0.0315\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0079 - val_loss: 0.0314\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.0079 - val_loss: 0.0318\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0078 - val_loss: 0.0314\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0078 - val_loss: 0.0310\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0078 - val_loss: 0.0310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f852871b130>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_split, x_train_augmented, validation_data=(x_test_split, x_test, y_test_regr), epochs=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
