{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import utils\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "def embed_and_translate(data, nrows, ncols):\n",
    "    ndata = np.zeros((len(data), nrows, ncols, 1), dtype='float32')\n",
    "    translations = np.empty((len(data), 2), dtype='float32')\n",
    "    width, height = data.shape[1], data.shape[2]\n",
    "    for i in range(len(data)):\n",
    "        x = np.random.randint(ncols-width)\n",
    "        y = np.random.randint(nrows-height)\n",
    "        ndata[i][x:x+width, y:y+height] = data[i] # rows, cols = height, width\n",
    "        translations[i][0] = x+(width//2)\n",
    "        translations[i][1] = y+(height//2)\n",
    "    return ndata, translations\n",
    "            \n",
    "n_splits = 16\n",
    "io_shape = (64,64,1)\n",
    "size = int(io_shape[0] // (n_splits**(1/2)))\n",
    "latent_dim = 16 * 4 # since we have 4x4-splits we need 4 times the latent space for a fair comparison.\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train_augmented, y_train = embed_and_translate(x_train, 64, 64)\n",
    "x_train_split = np.array([utils.split(x, size, size) for x in x_train_augmented], dtype='float32')\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test_augmented, y_test = embed_and_translate(x_test, 64, 64)\n",
    "x_test_split = np.array([utils.split(x, size, size) for x in x_test_augmented], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 32, 32, 32)        160       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 16, 16, 64)        8256      \n",
      "_________________________________________________________________\n",
      "pt_conv (Conv2D)             (None, 16, 16, 1)         65        \n",
      "_________________________________________________________________\n",
      "latent_conv (Conv2D)         (None, 2, 2, 16)          1040      \n",
      "_________________________________________________________________\n",
      "latent (Flatten)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8192)              532480    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "deconv1 (Conv2DTranspose)    (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "deconv2 (Conv2DTranspose)    (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "dec_out (Conv2DTranspose)    (None, 64, 64, 1)         289       \n",
      "=================================================================\n",
      "Total params: 579,250\n",
      "Trainable params: 579,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(input_shape=(64,64,1), name='enc_in'),\n",
    "        #tf.keras.layers.Conv2D(filters=int(32), kernel_size=(4,4), strides=(4,4), activation='relu', padding='valid', use_bias=True, name='conv1'),\n",
    "        tf.keras.layers.Conv2D(filters=int(32), kernel_size=(2,2), strides=(2,2), activation='relu', padding='valid', use_bias=True, name='conv1'),\n",
    "        tf.keras.layers.Conv2D(filters=int(64), kernel_size=(2,2), strides=(2,2), activation='relu', padding='valid', use_bias=True, name='conv2'),\n",
    "        tf.keras.layers.Conv2D(filters=1, kernel_size=(1,1), strides=(1,1), activation='sigmoid', padding='valid', name='pt_conv'),\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=(8,8), strides=(8,8), padding='valid', name='latent_conv', use_bias=True),\n",
    "        tf.keras.layers.Flatten(name='latent'),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=4*8*8*32, activation='relu', name='dense'),\n",
    "        tf.keras.layers.Reshape(target_shape=(2*8, 2*8, 32), name='reshape'),\n",
    "        tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name='deconv1'),\n",
    "        tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='deconv2'),\n",
    "        tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', name='dec_out')\n",
    "    ]\n",
    ")\n",
    "print(model.summary())\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0081 - val_loss: 0.0052\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0035 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_augmented, x_train_augmented, validation_data=(x_test_augmented, x_test_augmented), batch_size=32, epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Conv2D, Conv2DTranspose, Dense, Input, Reshape, concatenate, Activation, Dropout\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sys; sys.path.insert(0, '..')\n",
    "import utils\n",
    "\n",
    "class MultiSplit(Model):\n",
    "    def __init__(self, n_splits, latent_dim, io_shape):\n",
    "        super(MultiSplit, self).__init__()\n",
    "        n_filters = [32, 64]\n",
    "        size = int( io_shape[0] // (n_splits**(1/2)) )  # W = H\n",
    "        self.encoder = self._create_encoder(latent_dim//n_splits, (size, size,1), n_filters)\n",
    "        self.input_reshaper = utils.Reshaper((n_splits, size, size, 1), (size, size,1))\n",
    "        self.latent_reshaper = utils.Reshaper([latent_dim//n_splits], [latent_dim])\n",
    "        self.decoder = self._create_decoder(latent_dim, io_shape, n_filters)\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(x, training=False)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, x, training=True):\n",
    "        z = self.encode(x, training=training)\n",
    "        y_pred = self.decode(z ,training=training)\n",
    "        return y_pred\n",
    "        \n",
    "    def encode(self, x, training=True):\n",
    "        return self.encoder( self.input_reshaper(x) , training)\n",
    "    \n",
    "    def decode(self, z, training=True):\n",
    "        return self.decoder( self.latent_reshaper(z) , training)\n",
    "    \n",
    "    def _create_encoder(self, latent_dim, input_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=input_shape),\n",
    "#             Conv2D(filters=n_filters[0], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "#             Conv2D(filters=n_filters[1], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "            Conv2D(filters=int(32), kernel_size=(2,2), strides=(2,2), activation='relu', padding='valid', use_bias=True, name='conv1'),\n",
    "            Conv2D(filters=int(64), kernel_size=(2,2), strides=(2,2), activation='relu', padding='valid', use_bias=True, name='conv2'),\n",
    "            Conv2D(filters=1, kernel_size=(1,1), strides=(1,1), activation='sigmoid', padding='valid', name='pt_conv'),\n",
    "#             Conv2D(filters=16, kernel_size=(8,8), strides=(8,8), padding='valid', name='latent_conv', use_bias=True),\n",
    "            Flatten()\n",
    "#             Dense(units=latent_dim, activation='sigmoid')  #! Sigmoid activation\n",
    "        ], name='encoder')\n",
    "\n",
    "    def _create_decoder(self, latent_dim, io_shape, n_filters):\n",
    "        return Sequential([\n",
    "            Input(shape=(latent_dim)),\n",
    "            Reshape((8,8,1)),\n",
    "#             Flatten(),\n",
    "            Conv2D(filters=16, kernel_size=(8,8), strides=(8,8), padding='valid', name='latent_conv', use_bias=True),\n",
    "#             Dense(io_shape[0]//4 * io_shape[1]//4 * 8),  #! Reduce amount of neurons by 4.\n",
    "#             Reshape((io_shape[0]//4, io_shape[1]//4, 8)),\n",
    "#             Conv2DTranspose(filters=n_filters[1], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "#             Conv2DTranspose(filters=n_filters[0], kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'),\n",
    "#             Conv2DTranspose(filters=1, kernel_size=(3,3), padding='same'),\n",
    "#             Activation('sigmoid', name='decoder_out')\n",
    "            \n",
    "            Dense(units=4*8*8*32, activation='relu', name='dense'),\n",
    "            Reshape(target_shape=(2*8, 2*8, 32), name='reshape'),\n",
    "            Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name='deconv1'),\n",
    "            Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='deconv2'),\n",
    "            Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', name='dec_out')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 8, 8, 32)          160       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 4, 4, 64)          8256      \n",
      "_________________________________________________________________\n",
      "pt_conv (Conv2D)             (None, 4, 4, 1)           65        \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 8,481\n",
      "Trainable params: 8,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_3 (Reshape)          (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "latent_conv (Conv2D)         (None, 1, 1, 16)          1040      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 1, 8192)        139264    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "deconv1 (Conv2DTranspose)    (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "deconv2 (Conv2DTranspose)    (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "dec_out (Conv2DTranspose)    (None, 64, 64, 1)         289       \n",
      "=================================================================\n",
      "Total params: 177,553\n",
      "Trainable params: 177,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = MultiSplit(n_splits, latent_dim, io_shape)\n",
    "model.compile(loss='mse', optimizer='adam') # COMPILE AFTER WEIGHTS LOADED\n",
    "print(model.encoder.summary())\n",
    "print(model.decoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 4) for input Tensor(\"input_20:0\", shape=(None, 4), dtype=float32), but it was called on an input with incompatible shape (512, 16).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    <ipython-input-18-a8808b51d140>:24 train_step  *\n        loss = self.compiled_loss(y, y_pred)\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__  **\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1198 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10037 squared_difference\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3319 _create_op_internal\n        ret = Operation(\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1816 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 128 and 32 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](multi_split_5/sequential_5/dec_out/BiasAdd, IteratorGetNext:1)' with input shapes: [128,64,64,1], [32,64,64,1].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-914386dc91cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_augmented\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_augmented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 505\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    506\u001b[0m             *args, **kwds))\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    <ipython-input-18-a8808b51d140>:24 train_step  *\n        loss = self.compiled_loss(y, y_pred)\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__  **\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1198 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10037 squared_difference\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3319 _create_op_internal\n        ret = Operation(\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1816 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/don/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 128 and 32 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](multi_split_5/sequential_5/dec_out/BiasAdd, IteratorGetNext:1)' with input shapes: [128,64,64,1], [32,64,64,1].\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_split, x_train_augmented, validation_data=(x_test_split, x_test_augmented), batch_size=32, epochs=10, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
